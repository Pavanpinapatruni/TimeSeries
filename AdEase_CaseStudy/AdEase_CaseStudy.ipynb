{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c03022bb",
   "metadata": {},
   "source": [
    "# <center>AdEase Case Study</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855206e1",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "- AdEase is an ads and marketing-based company helping businesses elicit maximum clicks @ minimum cost.\n",
    "- AdEase is an ad infrastructure to help businesses promote themselves easily, effectively, and economically\n",
    "- AdEase is trying to understand the per page view report for different wikipedia\n",
    "pages for 550 days, and forecasting the number of views so that you can predict and optimize the ad placement for your clients.\n",
    "- By leveraging data science and time series, Ad Ease can forecast page visits for different languages.\n",
    "\n",
    "# What is expected?\n",
    "- You are working in the Data Science team of Ad ease trying to understand the per page view report for different wikipedia pages for 550 days, and forecasting the number of views so that you can predict and optimize the ad placement for your clients. You are provided with the data of 145k wikipedia pages and daily view count for each of them. Your clients belong to different regions and need data on how their ads will perform on pages in different languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a41499",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion\n",
    "\n",
    "- Read data from gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a5ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "# file_id = \"1AbCDEfGhIJklMNopQRstuVWxyz12345\"\n",
    "# output_path = \"train_1.csv\"          # rename if needed\n",
    "# gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)\n",
    "\n",
    "zip_id = \"11uLnI8MB1BSMzzI4ox1jK7jbAwsxdbqo\"\n",
    "zip_path = \"train_1.zip\"\n",
    "\n",
    "# Download the zip only if it doesn't already exist\n",
    "if not os.path.exists(zip_path):\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={zip_id}\", zip_path, quiet=False)\n",
    "else:\n",
    "    print(f\"{zip_path} already exists. Skipping download.\")\n",
    "\n",
    "# Extract directly into current working directory (no subfolder)\n",
    "# Skip extraction if the expected main file already exists\n",
    "expected_file = \"train_1.csv\"\n",
    "if not os.path.exists(expected_file):\n",
    "    with zipfile.ZipFile(zip_path) as z:\n",
    "        z.extractall(path=\".\")\n",
    "    print(\"Extraction complete to current directory.\")\n",
    "else:\n",
    "    print(f\"{expected_file} already present. Skipping extraction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85431133",
   "metadata": {},
   "source": [
    "## 2.Libraries\n",
    "Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries to analyze data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# libraries to visualize data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error as mse,\n",
    "    mean_absolute_error as mae,\n",
    "    mean_absolute_percentage_error as mape\n",
    ")\n",
    "\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b585431",
   "metadata": {},
   "source": [
    "## 3. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a005aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file into a pandas dataframe\n",
    "df = pd.read_csv('train_1.csv')\n",
    "# look at the datatypes of the columns\n",
    "print('*************************************************')\n",
    "print(df.info())\n",
    "print('*************************************************\\n')\n",
    "print('*************************************************')\n",
    "print(f'Shape of the dataset is {df.shape}')\n",
    "print('*************************************************\\n')\n",
    "print('*************************************************')\n",
    "print(f'Number of nan/null values in each column: \\n{df.isna().sum()}')\n",
    "print('*************************************************\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a0fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of unique values in each column: \\n{df.nunique()}')\n",
    "print('*************************************************\\n')\n",
    "print('*************************************************')\n",
    "print(f'Duplicate entries: \\n{df.duplicated().value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289ecee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566237f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62673011",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- There are **145063** entries with 551 columns,\n",
    "- Which means there are 145063 wikipedia pages with views for 550 days\n",
    "- There are null/missing values in each of the dates\n",
    "- But there are no **duplicates**\n",
    "- There are **145063** unique wikipedia pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8360a5",
   "metadata": {},
   "source": [
    " reading Exog_Campaign_eng file containing flag for each date indicating \n",
    " if those dates had a campaign/significant event which could have influenced\n",
    " the page views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6b7263",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = \"1GvWoXIxe1RaMWMSp1nNOw46Nxh_7vdzE\"\n",
    "output_path = \"Exog_Campaign_eng\"          # rename if needed\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exog_en = pd.read_csv('Exog_Campaign_eng')\n",
    "# look at the datatypes of the columns\n",
    "print('*************************************************')\n",
    "print(exog_en.info())\n",
    "print('*************************************************\\n')\n",
    "print('*************************************************')\n",
    "print(f'Shape of the dataset is {exog_en.shape}')\n",
    "print('*************************************************\\n')\n",
    "print('*************************************************')\n",
    "print(f'Number of nan/null values in each column: \\n{exog_en.isna().sum()}')\n",
    "print('*************************************************\\n')\n",
    "print('*************************************************')\n",
    "print(f'Number of unique values in each column: \\n{exog_en.nunique()}')\n",
    "print('*************************************************\\n')\n",
    "print('*************************************************')\n",
    "print(f'Duplicate entries: \\n{exog_en.duplicated().value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330a0478",
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51538ab1",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- For every **550** entries in **Exog_Campaign_eng** there are corresponding 550 days in the **train_1.csv** dataset\n",
    "- **No** null/missing values\n",
    "- **2** unique values - 1 ans 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0dce30",
   "metadata": {},
   "source": [
    "## 4. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fded42e",
   "metadata": {},
   "source": [
    "### 4.1 Date Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd29da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_columns = df.columns[1:]\n",
    "df[data_columns].isna().sum().plot(figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d575b81",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- The null values are keep decreasing with dates(time)\n",
    "- We can infer that pages which are launched recently will not have views prior to launch\n",
    "- We can fill those values with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59388eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[data_columns] = df[data_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b41512",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889bd119",
   "metadata": {},
   "source": [
    "### 4.2 Extract information from page column\n",
    "\n",
    "like\n",
    "- page name\n",
    "- Language\n",
    "- domain\n",
    "- Device type used to access data\n",
    "- access origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca039fc",
   "metadata": {},
   "source": [
    "### 4.2.Extracting Page name from page column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Page.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dfdcff",
   "metadata": {},
   "source": [
    "The page column contains data in the below format: \\\n",
    "**SPECIFIC NAME _ LANGUAGE.wikipedia.org _ ACCESS TYPE _ ACCESS ORIGIN** \\\n",
    "having information about page name, the domain, device type used to access the\n",
    "page, aso the request origin(spider or browser age\n",
    "2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a0b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_name(page):\n",
    "#     pattern = r'(.{0,})_(.{2}).wikipedia.org_'\n",
    "#     result = re.findall(pattern, page)\n",
    "#     if len(result) == 1:\n",
    "#         return result[0][0]\n",
    "#     else:\n",
    "#         return 'unknown'\n",
    "# df['name'] = df['Page'].apply(extract_name)\n",
    "# df[['Page', 'name']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d952eaff",
   "metadata": {},
   "source": [
    "**Why we commented above code?**\n",
    "- The above code findall tries to scan entire page name and lists with similar format\n",
    "- But re.search only returns the first entry which would be sufficient and fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343e3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_name(page):\n",
    "    try:\n",
    "        return re.search(r'^(.*?)_', page).group(1)\n",
    "    except:\n",
    "        return page\n",
    "    \n",
    "df['name'] = df.Page.apply(extract_page_name)\n",
    "df[['Page', 'name']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6143a9",
   "metadata": {},
   "source": [
    "### 4.2.2 Extracting Language from Page column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320172bd",
   "metadata": {},
   "source": [
    "re.search(r'_\\w{2}\\.wikipedia\\.org')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c13176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_langugage(page):\n",
    "    try:\n",
    "        return re.search(r'_(\\w{2})\\.wikipedia\\.org', page).group(1)\n",
    "    except:\n",
    "        return 'un'\n",
    "df['language'] = df.Page.apply(extract_langugage)\n",
    "print(df['language'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbebf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60868ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_name_mapping ={\n",
    "    'zh': 'Chinese',\n",
    "    'fr': 'French',\n",
    "    'en': 'English',\n",
    "    'un': 'unknown',\n",
    "    'ru': 'Russian',\n",
    "    'de': 'German',\n",
    "    'ja': 'Japanese',\n",
    "    'es': 'Spanish'\n",
    "}\n",
    "df['language'] = df['language'].map(language_name_mapping)\n",
    "df['language'].value_counts().plot(kind='bar', title='Number of pages by language')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c507ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## % pages of different languages\n",
    "round(df['language'].value_counts(normalize=True)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b7100b",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- Maximum number of pages are in English with 16.62%\n",
    "- Followed by Japanese with 14.08%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90955c8b",
   "metadata": {},
   "source": [
    "### 4.2.3 Extracting access type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_accessType(page):\n",
    "    try:\n",
    "        pattern = r'all-access|mobile-web|desktop'\n",
    "        return re.search(pattern, page).group(0)\n",
    "    except:\n",
    "        return 'un'\n",
    "df['access_type'] =df.Page.apply(extract_accessType)\n",
    "df['access_type'].value_counts().plot(kind='pie', autopct='%1.1f%%', title='% of pages with diffrent access type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd49487",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- Nearly half of the pages have all access\n",
    "- Rest half are either accessible on mobile or desktop with almost equal percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe91fef",
   "metadata": {},
   "source": [
    "### 4.2.4 Extracting access origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149420a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['access_origin'] = df['Page'].str.findall('spider|agents').apply(lambda x: x[0])\n",
    "df['access_origin'].value_counts().plot(kind='pie', autopct='%1.1f%%', title='% of pages with diffrent access origin')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d869f",
   "metadata": {},
   "source": [
    "### Observations\n",
    "- Most pages(75.9%) have **agents** as access origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7f8dad",
   "metadata": {},
   "source": [
    "## 5.Aggregating and Pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4637d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f55b35",
   "metadata": {},
   "source": [
    "**Aggregating on language by taking average views per language for each date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3401262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df.drop(columns=['Page', 'name', 'access_type', 'access_origin'])\n",
    "df_agg = df_agg.groupby(['language']).mean().T.reset_index()\n",
    "df_agg['index'] = pd.to_datetime(df_agg['index'])\n",
    "df_agg =df_agg.set_index('index')\n",
    "df_agg.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0890813b",
   "metadata": {},
   "source": [
    "### 5.1 Time Series plot for all languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed95079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.plot(figsize=(13,6), title='Average views per language over time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Views')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd69ebb",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "- English pages are the most visited pages\n",
    "- Followed by Spanish\n",
    "- English pages have **upward trend**\n",
    "- There is an **unusual peak** from **mid of July to end of August 2016** for **English** and **Russian** pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2542f3fb",
   "metadata": {},
   "source": [
    "## 6 Stationarity, Detrending, ACF and PACF plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68216dcd",
   "metadata": {},
   "source": [
    "### 6.1 Stationarity Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9f1bea",
   "metadata": {},
   "source": [
    "**Using Augmented Dickey-Fuller test to check for stationarity**\n",
    "- H0: The series is not stationary\n",
    "- H1: The series is stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09316ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adfuller_test(timeseries):\n",
    "    p_value = sm.tsa.stattools.adfuller(timeseries)[1]\n",
    "    if p_value <= 0.05:\n",
    "        print(\"Time series is stationary\")\n",
    "    else:\n",
    "        print(\"Time series is non-stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in df_agg.columns:\n",
    "    print(f'ADF test for {language}:')\n",
    "    adfuller_test(df_agg[language])\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0466be78",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "- Only **Spanish, Russian** page visits are **stationary**\n",
    "- **Chinese, English, French, German and Japanese** page visits are **not stationary**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c85fbf",
   "metadata": {},
   "source": [
    "Starting with **English**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_ts = df_agg['English']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e0128",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.plot(english_ts.index, english_ts)\n",
    "ax.plot(english_ts.index, (exog_en + 1)*3000, \":\") ## As english pages min mean is above 3000\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561f0b74",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "- From above plot the ts looks like linear upward trend and linear seasonality\n",
    "- Unusual spikes in page visits during the special events marked with orange peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7dbe1d",
   "metadata": {},
   "source": [
    "### 6.2 De-Trending and De-seasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_ts.diff(1).dropna().plot(figsize=(12, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef5cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller_test(english_ts.diff(1).dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c28929",
   "metadata": {},
   "source": [
    "Series become stationary by doing first order diffrencing => **d = 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deseasoning\n",
    "## check any small part of series\n",
    "english_ts[50:130].plot(figsize=(12,2))\n",
    "plt.show()\n",
    "english_ts[130:210].plot(figsize=(12,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd47d343",
   "metadata": {},
   "source": [
    "**Seasonality** is observed for every **7 days** ==> **s=7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a977163",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_ts.diff(1).diff(7).dropna().plot(figsize=(12,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f77d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller_test(english_ts.diff(1).diff(7).dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32599d53",
   "metadata": {},
   "source": [
    "As **Trend** and  **Seasonality** are removed manually, ADF test gives **time series is stationary**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e4f91b",
   "metadata": {},
   "source": [
    "### 6.3. Auto de-composition\n",
    "Auto decomposition using statsmodel library to decompose time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b1562",
   "metadata": {},
   "outputs": [],
   "source": [
    "decom = seasonal_decompose(english_ts)\n",
    "english_ts_trend = decom.trend\n",
    "english_ts_seasonal = decom.seasonal\n",
    "english_ts_res = decom.resid\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.subplot(411)\n",
    "plt.plot(english_ts, label = 'actual')\n",
    "plt.legend()\n",
    "plt.subplot(412)\n",
    "plt.plot(english_ts_trend, label = 'trend')\n",
    "plt.legend()\n",
    "plt.subplot(413)\n",
    "plt.plot(english_ts_seasonal, label = 'seasonal')\n",
    "plt.legend()\n",
    "plt.subplot(414)\n",
    "plt.plot(english_ts_res, label = 'residual')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08626ab0",
   "metadata": {},
   "source": [
    "### 6.4 ACF and PACF plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0da0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(12,3))\n",
    "plot_acf(ax=ax[0], x=english_ts.diff(1).dropna())\n",
    "plot_pacf(ax=ax[1], x=english_ts.diff(1).dropna())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb6a55",
   "metadata": {},
   "source": [
    "> - From the PACF plot, we can see that there are 3 significant lags, at 5, 7 and 21. So **P=1,2 or 3**\n",
    "> - From the ACF plot, we can see that there are 3 significant lags, at 7, 14 and 21. So **Q=1,2 or 3**\n",
    "> - From the PACF plot, the cut-off is right from lag 0 and same for ACF plot. hence, **p** and **q =  0 or 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e7ad38",
   "metadata": {},
   "source": [
    "## 7. Model building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb35f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to print values of all these metrics.\n",
    "def performance(actual, predicted, print_metrics=True):\n",
    "    MAE = round(mae(actual, predicted), 3)\n",
    "    RMSE = round(mse(actual, predicted)**0.5, 3)\n",
    "    MAPE = round(mape(actual, predicted), 3)\n",
    "    if(print_metrics==True):\n",
    "        print('MAE :', MAE)\n",
    "        print('RMSE :', RMSE)\n",
    "        print('MAPE:', MAPE)\n",
    "    return MAE, RMSE, MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d135905a",
   "metadata": {},
   "source": [
    "### 7.1 ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b7767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeries = english_ts.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe93ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_forecast = 60\n",
    "model = ARIMA(timeSeries[:-n_forecast], order=(0,1,0))\n",
    "model = model.fit()\n",
    "predicted = model.forecast(steps=n_forecast, alpha=0.05)\n",
    "plt.figure(figsize=(12,5))\n",
    "timeSeries.plot(label='Acutal')\n",
    "predicted.plot(label='Forecast', linestyle='dashed', marker='.')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "(_,_,_) = performance(timeSeries.values[-n_forecast:], predicted.values, print_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6420c0",
   "metadata": {},
   "source": [
    "model is not doing good job even for diff comb of p and q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6586e6ad",
   "metadata": {},
   "source": [
    "### 7.2 SARIMAX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70422ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1515845",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's try to include exogenous model\n",
    "exog = exog_en['Exog'].to_numpy()\n",
    "p,d,q,P,D,Q,S = 1,1,1,1,1,1,7\n",
    "n_forecast = 60\n",
    "model = SARIMAX(timeSeries[:-n_forecast], \n",
    "                order=(p,d,q), \n",
    "                seasonal_order=(P, D, Q, S), \n",
    "                exog= exog[:-n_forecast],\n",
    "                initialization='approximate_diffuse'\n",
    "                )\n",
    "model = model.fit()\n",
    "moder_forecast = model.forecast(steps=n_forecast, dynamic = True, exog = pd.DataFrame(exog[-n_forecast:]))\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "timeSeries[-100:].plot(label='Acutal')\n",
    "moder_forecast[-100:].plot(label = 'Forecast', color = 'red', linestyle='dashed', marker='o',markerfacecolor='green')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "(_,_,_) = performance(timeSeries.values[-n_forecast:], predicted.values, print_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78b594",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- SARIMAX model results are better, we need to do grid search to find the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd58e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SARIMAX_search(timeSeries, forecast, p_list, d_list, q_list, P_list, D_list, Q_list, s_list, exog=[]):\n",
    "    counter = 0\n",
    "    perf_df = pd.DataFrame(columns=['serial', 'pdq', 'PDQs', 'mape', 'rmse'])\n",
    "\n",
    "    for p in p_list:\n",
    "        for d in d_list:\n",
    "            for q in q_list:\n",
    "                for P in P_list:\n",
    "                    for D in D_list:\n",
    "                        for Q in Q_list:\n",
    "                            for s in s_list:\n",
    "                                try:\n",
    "                                    model = SARIMAX(timeSeries[:-n_forecast], \n",
    "                                                    order =(p,d,q), \n",
    "                                                    seasonal_order=(P, D, Q, s), \n",
    "                                                    exog = exog[:-n_forecast], \n",
    "                                                    initialization='approximate_diffuse'\n",
    "                                                    )\n",
    "                                    model = model.fit()\n",
    "                                    model_forecast = model.forecast(n_forecast, dynamic = True, exog = pd.DataFrame(exog[-n_forecast:]))\n",
    "                                    MAE, RMSE, MAPE = performance(timeSeries.values[-n_forecast:], model_forecast.values, print_metrics=False)\n",
    "                                    counter += 1\n",
    "                                    list_row = [counter, (p,d,q), (P,D,Q,s), MAPE, RMSE]\n",
    "                                    perf_df.loc[len(perf_df)] = list_row\n",
    "                                    print(f'Combination {counter} out of {(len(p_list)*len(d_list)*len(q_list)*len(P_list)*len(D_list)*len(Q_list)*len(s_list))}')\n",
    "                                except:\n",
    "                                    continue\n",
    "    return perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cbc460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "timeSeries = english_ts.copy(deep=True)\n",
    "n_forecast = 60\n",
    "p_list = [0,1]\n",
    "d_list = [1]\n",
    "q_list = [0,1]\n",
    "P_list = [2,3]\n",
    "D_list = [1]\n",
    "Q_list = [2,3]\n",
    "s_list = [7]\n",
    "exog = exog_en['Exog'].to_numpy()\n",
    "perf_df = SARIMAX_search(timeSeries, n_forecast, p_list, d_list, q_list, P_list, D_list, Q_list, s_list, exog)\n",
    "perf_df.sort_values(['mape', 'rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc6e3c1",
   "metadata": {},
   "source": [
    "p,d,q,P,D,Q,s = 1,1,1,2,1,3,7 gives lowest mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f343e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = exog_en['Exog'].to_numpy()\n",
    "p,d,q,P,D,Q,S = 1,1,1,2,1,3,7\n",
    "n_forecast = 60\n",
    "model = SARIMAX(timeSeries[:-n_forecast], \n",
    "                order=(p,d,q), \n",
    "                seasonal_order=(P, D, Q, S), \n",
    "                exog= exog[:-n_forecast],\n",
    "                initialization='approximate_diffuse'\n",
    "                )\n",
    "model = model.fit()\n",
    "moder_forecast = model.forecast(steps=n_forecast, dynamic = True, exog = pd.DataFrame(exog[-n_forecast:]))\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "timeSeries[-100:].plot(label='Acutal')\n",
    "moder_forecast[-100:].plot(label = 'Forecast', color = 'red', linestyle='dashed', marker='o',markerfacecolor='green')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "(_,_,_) = performance(timeSeries.values[-n_forecast:], moder_forecast.values, print_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfca179c",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- SARIMAX model has shown best results after tuning the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86788792",
   "metadata": {},
   "source": [
    "### 7.4 Facebook Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90254da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies for Prophet\n",
    "# %pip install cython\n",
    "# %pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412218ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeries = english_ts.copy(deep=True).reset_index()\n",
    "timeSeries = timeSeries[['index', 'English']]\n",
    "timeSeries.columns = ['ds', 'y']\n",
    "timeSeries['ds'] = pd.to_datetime(timeSeries['ds'])\n",
    "exog = exog_en['Exog']\n",
    "timeSeries['exog'] = exog.values\n",
    "timeSeries.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f3845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "model = Prophet(interval_width=0.95, weekly_seasonality=True)\n",
    "model.add_regressor('exog')\n",
    "n_forecast = 60\n",
    "model.fit(timeSeries)\n",
    "forecast_dates = model.make_future_dataframe(periods=0)\n",
    "forecast_dates['exog'] = timeSeries['exog']\n",
    "forecast = model.predict(forecast_dates)\n",
    "\n",
    "\n",
    "timeSeries['yhat'] = forecast['yhat']\n",
    "timeSeries['yhat_upper'] = forecast['yhat_upper']\n",
    "timeSeries['yhat_lower'] = forecast['yhat_lower']\n",
    "\n",
    "(_,_,_) = performance(timeSeries['y'], timeSeries['yhat'], print_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9e69f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(timeSeries['ds'], timeSeries['y'], label='Actual Visits', color='blue')\n",
    "plt.plot(timeSeries['ds'], timeSeries['yhat'], label='Predicted Visits', color='red', alpha=0.8)\n",
    "plt.fill_between(timeSeries['ds'], timeSeries['yhat_lower'], timeSeries['yhat_upper'], color='pink', alpha=0.3, label='Confidence Interval')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.title('Actual vs Predicted Visits')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88521e48",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- Prophet capturing more efficiently trend and unusual peak\n",
    "- Even seasonality capturing is very well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72e7d79",
   "metadata": {},
   "source": [
    "### **7.5 Other Langugages**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2074f7",
   "metadata": {},
   "source": [
    "### 7.5.1 Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12eccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeries = df_agg['Chinese'].copy(deep=True)\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(timeSeries.index, timeSeries)\n",
    "plt.show()\n",
    "\n",
    "timeSeries = timeSeries.reset_index()\n",
    "timeSeries = timeSeries[['index', 'Chinese']]\n",
    "timeSeries.columns = ['ds', 'y']\n",
    "timeSeries['ds'] = pd.to_datetime(timeSeries['ds'])\n",
    "timeSeries.tail()\n",
    "\n",
    "model = Prophet(interval_width=0.95, weekly_seasonality=True)\n",
    "model.fit(timeSeries)\n",
    "forecast_dates = model.make_future_dataframe(periods=0)\n",
    "forecast = model.predict(forecast_dates)\n",
    "\n",
    "timeSeries['yhat'] = forecast['yhat']\n",
    "timeSeries['yhat_upper'] = forecast['yhat_upper']\n",
    "timeSeries['yhat_lower'] = forecast['yhat_lower']\n",
    "\n",
    "(_,_,_) = performance(timeSeries['y'], timeSeries['yhat'], print_metrics=True)\n",
    "\n",
    "# Plot actual vs predicted visits\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(timeSeries['ds'], timeSeries['y'], label='Actual Visits', color='blue')\n",
    "plt.plot(timeSeries['ds'], timeSeries['yhat'], label='Predicted Visits', color='red', alpha=0.8)\n",
    "plt.fill_between(timeSeries['ds'], timeSeries['yhat_lower'], timeSeries['yhat_upper'], color='pink', alpha=0.3, label='Confidence Interval')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.title('Actual vs Predicted Visits')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa8877",
   "metadata": {},
   "source": [
    "### 7.5.2 French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ab420",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeries = df_agg['French'].copy(deep=True)\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(timeSeries.index, timeSeries)\n",
    "plt.show()\n",
    "\n",
    "timeSeries = timeSeries.reset_index()\n",
    "timeSeries = timeSeries[['index', 'French']]\n",
    "timeSeries.columns = ['ds', 'y']\n",
    "timeSeries['ds'] = pd.to_datetime(timeSeries['ds'])\n",
    "timeSeries.tail()\n",
    "\n",
    "model = Prophet(interval_width=0.95, weekly_seasonality=True)\n",
    "model.fit(timeSeries)\n",
    "forecast_dates = model.make_future_dataframe(periods=0)\n",
    "forecast = model.predict(forecast_dates)\n",
    "\n",
    "timeSeries['yhat'] = forecast['yhat']\n",
    "timeSeries['yhat_upper'] = forecast['yhat_upper']\n",
    "timeSeries['yhat_lower'] = forecast['yhat_lower']\n",
    "\n",
    "(_,_,_) = performance(timeSeries['y'], timeSeries['yhat'], print_metrics=True)\n",
    "\n",
    "# Plot actual vs predicted visits\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(timeSeries['ds'], timeSeries['y'], label='Actual Visits', color='blue')\n",
    "plt.plot(timeSeries['ds'], timeSeries['yhat'], label='Predicted Visits', color='red', alpha=0.8)\n",
    "plt.fill_between(timeSeries['ds'], timeSeries['yhat_lower'], timeSeries['yhat_upper'], color='pink', alpha=0.3, label='Confidence Interval')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.title('Actual vs Predicted Visits')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52fd9af",
   "metadata": {},
   "source": [
    "### 7.5.3 German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da76d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeries = df_agg['German'].copy(deep=True)\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(timeSeries.index, timeSeries)\n",
    "plt.show()\n",
    "\n",
    "timeSeries = timeSeries.reset_index()\n",
    "timeSeries = timeSeries[['index', 'German']]\n",
    "timeSeries.columns = ['ds', 'y']\n",
    "timeSeries['ds'] = pd.to_datetime(timeSeries['ds'])\n",
    "timeSeries.tail()\n",
    "\n",
    "model = Prophet(interval_width=0.95, weekly_seasonality=True)\n",
    "model.fit(timeSeries)\n",
    "forecast_dates = model.make_future_dataframe(periods=0)\n",
    "forecast = model.predict(forecast_dates)\n",
    "\n",
    "timeSeries['yhat'] = forecast['yhat']\n",
    "timeSeries['yhat_upper'] = forecast['yhat_upper']\n",
    "timeSeries['yhat_lower'] = forecast['yhat_lower']\n",
    "\n",
    "(_,_,_) = performance(timeSeries['y'], timeSeries['yhat'], print_metrics=True)\n",
    "\n",
    "# Plot actual vs predicted visits\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(timeSeries['ds'], timeSeries['y'], label='Actual Visits', color='blue')\n",
    "plt.plot(timeSeries['ds'], timeSeries['yhat'], label='Predicted Visits', color='red', alpha=0.8)\n",
    "plt.fill_between(timeSeries['ds'], timeSeries['yhat_lower'], timeSeries['yhat_upper'], color='pink', alpha=0.3, label='Confidence Interval')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.title('Actual vs Predicted Visits')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd620c08",
   "metadata": {},
   "source": [
    "### 7.5.4 Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3091fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeries = df_agg['Japanese'].copy(deep=True)\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(timeSeries.index, timeSeries)\n",
    "plt.show()\n",
    "\n",
    "timeSeries = timeSeries.reset_index()\n",
    "timeSeries = timeSeries[['index', 'Japanese']]\n",
    "timeSeries.columns = ['ds', 'y']\n",
    "timeSeries['ds'] = pd.to_datetime(timeSeries['ds'])\n",
    "timeSeries.tail()\n",
    "\n",
    "model = Prophet(interval_width=0.95, weekly_seasonality=True)\n",
    "model.fit(timeSeries)\n",
    "forecast_dates = model.make_future_dataframe(periods=0)\n",
    "forecast = model.predict(forecast_dates)\n",
    "\n",
    "timeSeries['yhat'] = forecast['yhat']\n",
    "timeSeries['yhat_upper'] = forecast['yhat_upper']\n",
    "timeSeries['yhat_lower'] = forecast['yhat_lower']\n",
    "\n",
    "(_,_,_) = performance(timeSeries['y'], timeSeries['yhat'], print_metrics=True)\n",
    "\n",
    "# Plot actual vs predicted visits\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(timeSeries['ds'], timeSeries['y'], label='Actual Visits', color='blue')\n",
    "plt.plot(timeSeries['ds'], timeSeries['yhat'], label='Predicted Visits', color='red', alpha=0.8)\n",
    "plt.fill_between(timeSeries['ds'], timeSeries['yhat_lower'], timeSeries['yhat_upper'], color='pink', alpha=0.3, label='Confidence Interval')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.title('Actual vs Predicted Visits')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a5437d",
   "metadata": {},
   "source": [
    "### 7.5.5 Russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e02359",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeries = df_agg['Russian'].copy(deep=True)\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(timeSeries.index, timeSeries)\n",
    "plt.show()\n",
    "\n",
    "timeSeries = timeSeries.reset_index()\n",
    "timeSeries = timeSeries[['index', 'Russian']]\n",
    "timeSeries.columns = ['ds', 'y']\n",
    "timeSeries['ds'] = pd.to_datetime(timeSeries['ds'])\n",
    "timeSeries.tail()\n",
    "\n",
    "model = Prophet(interval_width=0.95, weekly_seasonality=True)\n",
    "model.fit(timeSeries)\n",
    "forecast_dates = model.make_future_dataframe(periods=0)\n",
    "forecast = model.predict(forecast_dates)\n",
    "\n",
    "timeSeries['yhat'] = forecast['yhat']\n",
    "timeSeries['yhat_upper'] = forecast['yhat_upper']\n",
    "timeSeries['yhat_lower'] = forecast['yhat_lower']\n",
    "\n",
    "(_,_,_) = performance(timeSeries['y'], timeSeries['yhat'], print_metrics=True)\n",
    "\n",
    "# Plot actual vs predicted visits\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(timeSeries['ds'], timeSeries['y'], label='Actual Visits', color='blue')\n",
    "plt.plot(timeSeries['ds'], timeSeries['yhat'], label='Predicted Visits', color='red', alpha=0.8)\n",
    "plt.fill_between(timeSeries['ds'], timeSeries['yhat_lower'], timeSeries['yhat_upper'], color='pink', alpha=0.3, label='Confidence Interval')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.title('Actual vs Predicted Visits')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043a52d2",
   "metadata": {},
   "source": [
    "### 7.5.6 Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeries = df_agg['Spanish'].copy(deep=True)\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(timeSeries.index, timeSeries)\n",
    "plt.show()\n",
    "\n",
    "timeSeries = timeSeries.reset_index()\n",
    "timeSeries = timeSeries[['index', 'Spanish']]\n",
    "timeSeries.columns = ['ds', 'y']\n",
    "timeSeries['ds'] = pd.to_datetime(timeSeries['ds'])\n",
    "timeSeries.tail()\n",
    "\n",
    "model = Prophet(interval_width=0.95, weekly_seasonality=True)\n",
    "model.fit(timeSeries)\n",
    "forecast_dates = model.make_future_dataframe(periods=0)\n",
    "forecast = model.predict(forecast_dates)\n",
    "\n",
    "timeSeries['yhat'] = forecast['yhat']\n",
    "timeSeries['yhat_upper'] = forecast['yhat_upper']\n",
    "timeSeries['yhat_lower'] = forecast['yhat_lower']\n",
    "\n",
    "(_,_,_) = performance(timeSeries['y'], timeSeries['yhat'], print_metrics=True)\n",
    "\n",
    "# Plot actual vs predicted visits\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(timeSeries['ds'], timeSeries['y'], label='Actual Visits', color='blue')\n",
    "plt.plot(timeSeries['ds'], timeSeries['yhat'], label='Predicted Visits', color='red', alpha=0.8)\n",
    "plt.fill_between(timeSeries['ds'], timeSeries['yhat_lower'], timeSeries['yhat_upper'], color='pink', alpha=0.3, label='Confidence Interval')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.title('Actual vs Predicted Visits')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0297e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
